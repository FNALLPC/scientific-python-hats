{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing a dijet analysis, we'll want to use TLorentzVectors to do things like computing the invariant mass of a two-jet system. But TLorentzVectors are notoriously slow in pyROOT. Even if this weren't the case, looping over big trees is really something you should never do in pyROOT. But pretty much everything besides those CPU-intensive tasks is better in pyROOT :-P\n",
    "\n",
    "Please take a look at the minimal changes made to `hatsTrees.C` and `hatsTrees.h` that you can find in the `sample_code` directory. A good philosophy with using `TTree.MakeClass()` is to change as little as possible. Please read the below diff -- it contains useful tips on e.g. setting up the class to take arguments. Without the comments, there are about 30 lines of code added, but they're sufficient for all the heavy lifting in the calculation of complicated physical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!diff hatsTrees.C sample_code/hatsTrees.C  # could try adding --side-by-side to this command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've prepared our C++ class to do the heavy lifting, we will create a python-environment script where we can load it and use it to process our big datasets, while leveraging python to do the things that are annoying in C++. We'll design it to be suitable for use in batch submissions. Please follow along by looking at sample_code/runHatsTrees.py \n",
    "> Now let's go through `runHatsTrees.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that runHatsTrees.py has an OptionParser defined. OptionParser is a commonly used bit of python that will automatically generate a help message for someone trying to use the script. Let's see what it says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sample_code/runHatsTrees.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try running it according to the help message (this will take some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sample_code/runHatsTrees.py -i /store/user/hats/PyRoot/2017/qcd_samples/QCD_HT1000to1500_0_0 -o hatsTrees_QCD_HT700to1000_0_0.root -t \"ntuplizer/tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which xrdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did we just process? We can check using the XRootD bindings for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from XRootD import client\n",
    "xrdClient = client.FileSystem(\"root://cmseos.fnal.gov/\")\n",
    "\n",
    "processedDir = \"/store/user/hats/PyRoot/2017/qcd_samples/QCD_HT700to1000_0_0/\"\n",
    "(status, files) = xrdClient.dirlist(processedDir)\n",
    "bytes = 0\n",
    "for file in files:\n",
    "    (status, info) = xrdClient.stat(processedDir + file.name)\n",
    "    bytes += info.size\n",
    "print \"bytes:\", bytes\n",
    "print \"gigabytes:\", bytes/float(1024**3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that our output looks reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT as r\n",
    "firstHatsFile = r.TFile(\"output/hatsTrees_QCD_HT700to1000_0_0.root\")\n",
    "firstHatsFile.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstHatsTree = firstHatsFile.Get(\"hatsDijets\")\n",
    "firstHatsTree.Print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can = r.TCanvas()\n",
    "can.SetLogy()\n",
    "firstHatsTree.Draw(\"dijetMass\")\n",
    "can.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen that our python script works running over one of our input files, we're ready to do a batch submission to process all of our ntuples. However, during this HATS session, we won't actually submit the jobs. They have been made already and you can find them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!xrdfs root://xrootd.accre.vanderbilt.edu ls /store/user/hats/PyRoot/2017/hatsDijetTrees/ | sort -u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in using a python script of this sort in batch submission, please see `sample_code/condorSubmission` for an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ">Please continue on in `backgroundHists.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hats-sci-py",
   "language": "python",
   "name": "hats-sci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
