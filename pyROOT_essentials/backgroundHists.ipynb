{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our hatsTrees that have the interesting physical variables calculated, let's do some analysis with them. To combine our MC background samples, we will need to compute weights for them. Fortunately, we have these defined in python `.ini` files.\n",
    "\n",
    "`.ini` files are a standard format for python configuration files. They have a simple syntax and are quite flexible -- this is another example of where python can help us from falling in the trap of re-inventing the wheel by writing custom code for every simple task, like parsing text files.\n",
    "\n",
    "Let's take a look at `hatsConfig.ini`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat hatsConfig.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ConfigParser import RawConfigParser\n",
    "config = RawConfigParser()   \n",
    "config.optionxform = str       # Last two lines are done because ConfigParser will not preserve case\n",
    "config.read(\"hatsConfig.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a nifty way to create a dict of the cross sections and number of events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossSections = dict([sample, float(xsec)] for sample, xsec in config.items('hatsXsects'))\n",
    "nProcessed    = dict([sample, int(nPro)] for sample, nPro in config.items('hatsNprocessed'))\n",
    "\n",
    "from pprint import pprint\n",
    "print \"cross sections:\" \n",
    "pprint(crossSections)\n",
    "print \"number of events processed:\"\n",
    "pprint(nProcessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python `dict`s are extremely useful, because we can give descriptive names to the data they hold. Let's use our dicts to calculate the weights for our MC background samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "luminosity = 1.42    # This is just an example value\n",
    "for sample in crossSections.keys():\n",
    "    weights[sample] = luminosity * crossSections[sample]/nProcessed[sample]\n",
    "pprint(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the Python XRootD bindings to access all of our input files. Since our input files live on eos, we follow the recommendations on http://uscms.org/uscms_at_work/computing/LPC/usingEOSAtLPC.shtml, which instructs us to always list and open files via XRootD. First, we can use the Python XRootD files to look at our input directory, as we did in firstLook.ipynb using shell commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from XRootD import client\n",
    "xrdClient = client.FileSystem(\"root://cmseos.fnal.gov//\")\n",
    "hatsTreesDir = \"//store/user/hats/PyRoot/2017/hatsDijetTrees\"\n",
    "status, dirList = xrdClient.dirlist(hatsTreesDir)\n",
    "for entry in dirList:\n",
    "    print \"file host:\", entry.hostaddr, \"  file name:\", entry.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ROOT to open the input file, it will want a full url in the form `root://host:port//the/location/on/eos/file.root`. So we can make a dict to store what we need to build a full url, using a clever list comprehension. In the dict, we will store a tuple that separates out the logical filename from the rest of the full url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "sampleDirURLs = {}\n",
    "for sample in crossSections.keys():\n",
    "    [matchingDir] = [(\"root://\" + entry.hostaddr, path.join(hatsTreesDir, entry.name)) for entry in dirList if sample in entry.name]\n",
    "    sampleDirURLs[sample]=matchingDir  \n",
    "pprint(sampleDirURLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can make dicts to hold TChains of all our data, and then draw them with weights. Also in this cell, we use the Python bindings for XRootD to generate our list of input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatsChains = {}\n",
    "import ROOT as r\n",
    "r.gDebug = 1\n",
    "for sample in crossSections.keys():\n",
    "    chain = r.TChain('hatsDijets')\n",
    "    status, fileList = xrdClient.dirlist(sampleDirURLs[sample][1]) # dirlist takes the logical filename\n",
    "    for hatsFile in fileList:\n",
    "        chain.Add(sampleDirURLs[sample][0] + path.join(sampleDirURLs[sample][1], hatsFile.name))  # ROOT takes the full url\n",
    "    hatsChains[sample] = chain\n",
    "pprint(hatsChains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to make weighted histograms of all the MC backgrounds using TChain.Draw(), and put them into a stackplot. Here we run into a classic pyROOT gotcha: it's not easy to prevent root from garbage collecting your histograms. It's best to keep them in a list or dict that isn't within the scope of a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onechain = hatsChains['QCD_HT1000to1500']\n",
    "for chain in hatsChains:\n",
    "    print \"%s: %s\" % (chain, len(hatsChains[chain].GetListOfFiles()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the plots -- this will take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {}\n",
    "import sys\n",
    "for sample in crossSections.keys():\n",
    "    print \"Processing %s\" % sample\n",
    "    varNames=[]\n",
    "    sys.stderr.write(\"Sample: %s\\n\" % sample)\n",
    "    for var in hatsChains[sample].GetListOfBranches():\n",
    "        varNames.append(var.GetName())\n",
    "    for varName in varNames:\n",
    "        sys.stderr.write(\"  varName: %s\\n\" % varName)\n",
    "        histLabel = \"%s_%s\" % (varName, sample)\n",
    "        hists[histLabel]=r.TH1F(histLabel, histLabel, 100, 0, 0)\n",
    "        hatsChains[sample].Draw(\"%s>>%s\" % (varName, histLabel))\n",
    "\n",
    "pprint(hists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've made histograms of all our variables in all our samples, we can put together stack plots of them all. We will leave that as an exercise to work on for the rest of the HATS. The histograms are organized in a dictionary that you should be able to navigate easily using their keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = r.TCanvas()\n",
    "hists[\"cosThetaStar_QCD_HT1000to1500\"].Draw()\n",
    "canvas.Draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hats-sci-py",
   "language": "python",
   "name": "hats-sci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
