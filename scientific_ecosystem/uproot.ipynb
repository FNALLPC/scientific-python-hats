{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# uproot\n",
    "\n",
    "ROOT data to Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are several ways to get data from ROOT files into Numpy arrays.\n",
    "\n",
    "   * Iteration in PyROOT (super slow!)\n",
    "   * ROOT's new `TTree::AsMatrix` (flat data, simple types)\n",
    "   * root_numpy (compiles against a ROOT version; slow for variable number of objects per event)\n",
    "   * uproot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unlike all of the above, uproot is a *reimplementation* of ROOT I/O that skips unnecessary steps between deserialization and array filling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "uproot uses Numpy vectorization for anything that scales with the number of events, Python for the complex business of navigating the file.\n",
    "\n",
    "For larger (fewer) baskets, there's less navigation and more vectorization. ROOT builds objects for the convenience of physics C++ code, but when dumping into arrays, we don't want that.\n",
    "\n",
    "<table>\n",
    "  <tr style=\"background-color: white;\">\n",
    "    <td style=\"text-align: center; border-bottom: none; font-size: 18pt;\">Speedup relative to ROOT vs basket size</td>\n",
    "    <td style=\"text-align: center; border-bottom: none; font-size: 18pt;\">Speedup relative to root_numpy vs basket size</td>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: white;\">\n",
    "    <td><img src=\"img/uproot_root-none-muon.png\"></td>\n",
    "    <td><img src=\"img/uproot_rootnumpy-none-muon.png\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = uproot.open(\"~/data/DYJetsToLL.root\")[\"Events\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dropping data into machine learning libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define a 2 hidden layer neural network in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SimpleNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden1_dim, hidden2_dim, output_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(input_dim, hidden1_dim)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(hidden1_dim, hidden2_dim)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.layer3 = torch.nn.Linear(hidden2_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer3(self.relu2(self.layer2(self.relu1(self.layer1(x)))))\n",
    "\n",
    "# 25 input parameters, 20 node hidden layer, 10 node hidden layer, 1 output\n",
    "simplenn = SimpleNN(25, 20, 10, 1)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(simplenn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The 25 input parameters are jet attributes other than the btag.\n",
    "\n",
    "The 1 output is the supervised learning target: Jet_btagCMVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7388405, 25), (7388405, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jetarrays = events.arrays(\"Jet_*\")\n",
    "\n",
    "inputs = numpy.vstack(jetarrays[n] for n in sorted(jetarrays) if not n.startswith(\"Jet_btag\")).T.astype(\"float32\")\n",
    "expected_output = numpy.array(jetarrays[\"Jet_btagCMVA\"]).reshape(-1, 1)\n",
    "\n",
    "inputs.shape, expected_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "PyTorch, like all other Pythonic ML libraries, has methods to get batches of data from Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "inputs = torch.autograd.Variable(torch.from_numpy(inputs))\n",
    "expected_output = torch.autograd.Variable(torch.from_numpy(expected_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And now we use PyTorch; it doesn't matter where the data came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4066)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "computed_output = simplenn.forward(inputs)\n",
    "loss = criterion(computed_output, expected_output)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
